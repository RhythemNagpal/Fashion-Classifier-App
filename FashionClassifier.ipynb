{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "FashionClassifier.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "p8bO0hupMdZM"
      },
      "source": [
        "## Preparation\n",
        "\n",
        "Let's start by importing TensorFlow and other supporting libraries that are used for data processing and visualization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nImr6z7TMBJQ",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Rivc81WyRpXG"
      },
      "source": [
        "Import MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZGd5hkioMpcr",
        "colab": {}
      },
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# Normalize the input image so that each pixel value is between 0 to 1.\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Add a color dimension to the images in \"train\" and \"validate\" dataset to\n",
        "# leverage Keras's data augmentation utilities later.\n",
        "train_images = np.expand_dims(train_images, axis=3)\n",
        "test_images = np.expand_dims(test_images, axis=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0SbDbl3HSHh1"
      },
      "source": [
        "Define an utility function so that we can create quickly create multiple models with the same model architecture for comparison."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JjoUeI5WSE_H",
        "colab": {}
      },
      "source": [
        "def create_model():\n",
        "  model = keras.Sequential([\n",
        "    keras.layers.InputLayer(input_shape=(28, 28, 1)),\n",
        "    keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation=tf.nn.relu),\n",
        "    keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation=tf.nn.relu),\n",
        "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    keras.layers.Dropout(0.25),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "  ])\n",
        "  model.compile(optimizer='adam',\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QGgIJ4pYThkm"
      },
      "source": [
        "Confirm that our model can achieve above 98% accuracy on MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W2cYWUbkTb8Q",
        "colab": {}
      },
      "source": [
        "base_model = create_model()\n",
        "base_model.fit(\n",
        "    train_images,\n",
        "    train_labels,\n",
        "    epochs=5,\n",
        "    validation_data=(test_images, test_labels)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lEtLCGS0Ufag"
      },
      "source": [
        "# Troubleshoot the accuracy drop\n",
        "\n",
        "Let's see the digit images in MNIST again and guess the cause of the accuracy drop we experienced in deployment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xptCfTnBTgvm",
        "colab": {}
      },
      "source": [
        "# Show the first 25 images in the training dataset.\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "  plt.subplot(5,5,i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.grid(False)\n",
        "  plt.imshow(np.squeeze(train_images[i], axis=2), cmap=plt.cm.gray)\n",
        "  plt.xlabel(train_labels[i])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "phB_hWqFWOQR"
      },
      "source": [
        "We can see from the 25 images above that the digits are about the same size, and they are in the center of the images. Let's verify if this assumption is true across the MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2V0KsvSLVE6I",
        "colab": {}
      },
      "source": [
        "# An utility function that returns where the digit is in the image.\n",
        "def digit_area(mnist_image):\n",
        "  # Remove the color axes\n",
        "  mnist_image = np.squeeze(mnist_image, axis=2)\n",
        "\n",
        "  # Extract the list of columns that contain at least 1 pixel from the digit\n",
        "  x_nonzero = np.nonzero(np.amax(mnist_image, 0))\n",
        "  x_min = np.min(x_nonzero)\n",
        "  x_max = np.max(x_nonzero)\n",
        "\n",
        "  # Extract the list of rows that contain at least 1 pixel from the digit\n",
        "  y_nonzero = np.nonzero(np.amax(mnist_image, 1))\n",
        "  y_min = np.min(y_nonzero)\n",
        "  y_max = np.max(y_nonzero)\n",
        "\n",
        "  return [x_min, x_max, y_min, y_max]\n",
        "\n",
        "# Calculate the area containing the digit across MNIST dataset\n",
        "digit_area_rows = []\n",
        "for image in train_images:\n",
        "  digit_area_row = digit_area(image)\n",
        "  digit_area_rows.append(digit_area_row)\n",
        "digit_area_df = pd.DataFrame(\n",
        "  digit_area_rows,\n",
        "  columns=['x_min', 'x_max', 'y_min', 'y_max']\n",
        ")\n",
        "digit_area_df.hist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AC5l3W7bY1td",
        "colab": {}
      },
      "source": [
        "# Define data augmentation\n",
        "datagen = keras.preprocessing.image.ImageDataGenerator(\n",
        "  rotation_range=30,\n",
        "  width_shift_range=0.25,\n",
        "  height_shift_range=0.25,\n",
        "  shear_range=0.25,\n",
        "  zoom_range=0.2,\n",
        "  horizontal_flip=True,\n",
        "  fill_mode=\"nearest\",\n",
        "\n",
        ")\n",
        "\n",
        "# Generate augmented data from MNIST dataset\n",
        "train_generator = datagen.flow(train_images, train_labels)\n",
        "test_generator = datagen.flow(test_images, test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wy1IfuRZjjec"
      },
      "source": [
        "Let's see what our digit images look like after augmentation. You can see that we now clearly have much more variation on how the digits are placed in the images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1G-tWDc2aia1",
        "colab": {}
      },
      "source": [
        "augmented_images, augmented_labels = next(train_generator)\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(np.squeeze(augmented_images[i], axis=2), cmap=plt.cm.gray)\n",
        "    plt.xlabel('Label: %d' % augmented_labels[i])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "G-zys-yNkL4b"
      },
      "source": [
        "Let's evaluate the digit classifier model that we trained earlier on this augmented test dataset and see if it makes accuracy drop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IPnP4xPbjqWi",
        "colab": {}
      },
      "source": [
        "base_model.evaluate(test_generator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AgNlTPPVlDqX"
      },
      "source": [
        "You can see that accuracy significantly dropped to below 40% in augmented test dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Xls8oqBnlcZj"
      },
      "source": [
        "# Improve accuracy with data augmentation\n",
        "\n",
        "Now let's train our model using augmented dataset to make it perform better in deployment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DX4XRgc9k-6s",
        "colab": {}
      },
      "source": [
        "improved_model = create_model()\n",
        "improved_model.fit(train_generator, epochs=15, validation_data=test_generator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3UlqZ1XnnJRu"
      },
      "source": [
        "We can see that as the models saw more distorted digit images during training, its accuracy evaluated distorted test digit images were significantly improved to about 90%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fsI4mHtbpE_A"
      },
      "source": [
        "# Convert to TensorFlow Lite\n",
        "\n",
        "Let's convert the improved model to TensorFlow Lite and redeploy to the Android app."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a0l6HcBTmh7-",
        "colab": {}
      },
      "source": [
        "# Convert Keras model to TF Lite format and quantize.\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(improved_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_quantized_model = converter.convert()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WR769sha6B-R",
        "colab_type": "text"
      },
      "source": [
        "##Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgeOcW806KdX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A helper function to evaluate the TF Lite model using \"test\" dataset.\n",
        "def evaluate_tflite_model(tflite_model):\n",
        "  # Initialize TFLite interpreter using the model.\n",
        "  interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "  interpreter.allocate_tensors()\n",
        "  input_tensor_index = interpreter.get_input_details()[0][\"index\"]\n",
        "  output = interpreter.tensor(interpreter.get_output_details()[0][\"index\"])\n",
        "\n",
        "  # Run predictions on every image in the \"test\" dataset.\n",
        "  prediction_digits = []\n",
        "  for test_image in test_images:\n",
        "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
        "    # the model's input data format.\n",
        "    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
        "    interpreter.set_tensor(input_tensor_index, test_image)\n",
        "\n",
        "    # Run inference.\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # Post-processing: remove batch dimension and find the digit with highest\n",
        "    # probability.\n",
        "    digit = np.argmax(output()[0])\n",
        "    prediction_digits.append(digit)\n",
        "\n",
        "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
        "  accurate_count = 0\n",
        "  for index in range(len(prediction_digits)):\n",
        "    if prediction_digits[index] == test_labels[index]:\n",
        "      accurate_count += 1\n",
        "  accuracy = accurate_count * 1.0 / len(prediction_digits)\n",
        "\n",
        "  return accuracy\n",
        "\n",
        "quantized_accuracy = evaluate_tflite_model(tflite_quantized_model)\n",
        "print('Quantized model accuracy = %.4f' % quantized_accuracy)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "it7HDEUD6LsW",
        "colab_type": "text"
      },
      "source": [
        "##Download the TensorFlow Lite model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_x5MGp3y6Vag",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the quantized model to file to the Downloads directory\n",
        "f = open('fashion_mnist.tflite', \"wb\")\n",
        "f.write(tflite_quantized_model)\n",
        "f.close()\n",
        "\n",
        "# Download the digit classification model\n",
        "from google.colab import files\n",
        "files.download('fashion_mnist.tflite')\n",
        "\n",
        "print('`fashion_mnist.tflite` has been downloaded')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}